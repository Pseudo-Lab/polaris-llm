{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 실행 후 마지막 ngrok url을 streamlit url에 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Downloading ollama...\n",
      "######################################################################## 100.0%\n",
      ">>> Installing ollama to /usr/local/bin...\n",
      ">>> Adding ollama user to render group...\n",
      ">>> Adding ollama user to video group...\n",
      ">>> Adding current user to ollama group...\n",
      ">>> Creating ollama systemd service...\n",
      "Failed to connect to bus: No such file or directory\n",
      ">>> NVIDIA GPU installed.\n",
      ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
      ">>> Install complete. Run \"ollama\" from the command line.\n",
      "Hit:1 https://cli.github.com/packages stable InRelease\n",
      "Hit:2 http://security.ubuntu.com/ubuntu focal-security InRelease               \n",
      "Hit:3 https://download.docker.com/linux/ubuntu focal InRelease                 \n",
      "Hit:4 https://nvidia.github.io/libnvidia-container/stable/deb/amd64  InRelease \n",
      "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
      "Hit:6 http://archive.ubuntu.com/ubuntu focal InRelease                         \n",
      "Hit:7 https://ngrok-agent.s3.amazonaws.com buster InRelease\n",
      "Hit:8 http://archive.ubuntu.com/ubuntu focal-updates InRelease\n",
      "Hit:9 http://archive.ubuntu.com/ubuntu focal-backports InRelease\n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "cuda-drivers is already the newest version (555.42.02-1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 5 not upgraded.\n",
      "Requirement already satisfied: pyngrok in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (7.1.6)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pyngrok) (6.0.1)\n"
     ]
    }
   ],
   "source": [
    "#!pip install pyngrok==4.1.1.\n",
    "!curl -fsSL https://ollama.com/install.sh | sh\n",
    "!echo 'debconf debconf/frontend select Noninteractive' | sudo debconf-set-selections\n",
    "!sudo apt-get update && sudo apt-get install -y cuda-drivers\n",
    "!pip install pyngrok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyngrok import ngrok\n",
    "with open('b2ft_ngrok_cred.txt', 'r') as f:\n",
    "  token = [r.strip() for r in f.readlines()]\n",
    "#print(token)\n",
    "ngrok.set_auth_token(token[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "\n",
    "# set LD_LIBRARY_PATH\n",
    "os.environ.update({'LD_LIBRARY_PATH': '/usr/lib64-nvidia'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> starting ollama serve\n",
      ">>> starting ngrok http --log stderr 11434 --host-header=\"localhost:11434\"\n",
      ">>> starting ollama pull gemma:7b-instruct\n",
      "Error: listen tcp 127.0.0.1:11434: bind: address already in use\n",
      "t=2024-06-15T04:14:13+0000 lvl=info msg=\"no configuration paths supplied\"\n",
      "t=2024-06-15T04:14:13+0000 lvl=info msg=\"using configuration at default config path\" path=/teamspace/studios/this_studio/.config/ngrok/ngrok.yml\n",
      "t=2024-06-15T04:14:13+0000 lvl=info msg=\"open config file\" path=/teamspace/studios/this_studio/.config/ngrok/ngrok.yml err=nil\n",
      "t=2024-06-15T04:14:13+0000 lvl=warn msg=\"can't bind default web address, trying alternatives\" obj=web addr=127.0.0.1:4040\n",
      "t=2024-06-15T04:14:13+0000 lvl=info msg=\"starting web service\" obj=web addr=127.0.0.1:4042 allow_hosts=[]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t=2024-06-15T04:14:13+0000 lvl=info msg=\"client session established\" obj=tunnels.session\n",
      "t=2024-06-15T04:14:13+0000 lvl=info msg=\"tunnel session started\" obj=tunnels.session\n",
      "t=2024-06-15T04:14:13+0000 lvl=info msg=\"started tunnel\" obj=tunnels name=command_line addr=http://localhost:11434 url=https://b5d4-3-91-245-82.ngrok-free.app\n",
      "\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest\n",
      "pulling ef311de6af9d... 100% ▕████████████████▏ 5.0 GB\n",
      "pulling 097a36493f71... 100% ▕████████████████▏ 8.4 KB\n",
      "pulling 109037bec39c... 100% ▕████████████████▏  136 B\n",
      "pulling 65bb16cf5983... 100% ▕████████████████▏  109 B\n",
      "pulling 0c2a5137eb3c... 100% ▕████████████████▏  483 B\n",
      "verifying sha256 digest\n",
      "writing manifest\n",
      "removing any unused layers\n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "# 이 부분 코드 실행하고 나서, 처음에 등장하는 ngrok url 주소를 따로 저장해주셔야 합니다.\n",
    "# 예시 : 아래에서 https://71e8-35-237-75-201.ngrok-free.app\n",
    "#  t=2024-05-24T03:29:01+0000 lvl=info msg=\"started tunnel\" obj=tunnels name=command_line addr=http://localhost:11434 url=https://71e8-35-237-75-201.ngrok-free.app\n",
    "\n",
    "\n",
    "async def run_process(cmd):\n",
    "  print('>>> starting', *cmd)\n",
    "  p = await asyncio.subprocess.create_subprocess_exec(\n",
    "      *cmd,\n",
    "      stdout=asyncio.subprocess.PIPE,\n",
    "      stderr=asyncio.subprocess.PIPE,\n",
    "  )\n",
    "\n",
    "  async def pipe(lines):\n",
    "    async for line in lines:\n",
    "      print(line.strip().decode('utf-8'))\n",
    "\n",
    "  await asyncio.gather(\n",
    "      pipe(p.stdout),\n",
    "      pipe(p.stderr),\n",
    "  )\n",
    "from IPython.display import clear_output\n",
    "clear_output()\n",
    "\n",
    "\n",
    "await asyncio.gather(\n",
    "run_process(['ollama', 'serve']),\n",
    "run_process(['ngrok', 'http', '--log', 'stderr', '11434', '--host-header=\"localhost:11434\"']),\n",
    "run_process(['ollama', 'pull', 'gemma:7b-instruct']), # 사용할 모델 pull하는 부분\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
