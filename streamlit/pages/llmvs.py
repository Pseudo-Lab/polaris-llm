import streamlit as st
from langchain_community.chat_models import ChatOllama

gemma = 'gemma:7b-instruct'
llama = 'llama3:8b'

def get_response(model, prompt, url):
    model_gemma = ChatOllama(
        model=model, temperature=0, base_url=url, verbose=True
    )
    return model_gemma.stream(prompt)


with st.sidebar:
    ollama_ngrok_url = st.text_input("Ollama Ngrok URL", key="ollama_ngrok_url")


st.title("ğŸ’¬ ë‹¹ì‹  ì‚¶ì˜ ë¶ê·¹ì„±ì€ ë¬´ì—‡ì¸ê°€ìš”?:star:")
st.caption("ğŸš€ ë¶ê·¹ì„± ì°¾ê¸°!!")


if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "ë‹¹ì‹ ì˜ ê¿ˆì€ ë¬´ì—‡ì¼ê¹Œìš”?"}]


for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

if prompt := st.chat_input():
    if not ollama_ngrok_url:
        st.info("Please add your ngrok_url to continue.")
        st.stop()

    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)

    # í˜¸ì¶œ ë° ì „ì²˜ë¦¬
    with st.chat_message(gemma):
        with st.spinner("ëŒ€ë‹µ ì¤‘ ..."):
            response = st.write_stream(get_response(model=gemma, prompt=prompt, url=ollama_ngrok_url))
    st.session_state.messages.append({"role": gemma, "content": response})

    with st.chat_message(llama):
        with st.spinner("ëŒ€ë‹µ ì¤‘ ..."):
            response = st.write_stream(get_response(model=llama, prompt=prompt, url=ollama_ngrok_url))
    st.session_state.messages.append({"role": llama, "content": response})

